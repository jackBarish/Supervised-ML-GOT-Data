{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f5574b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    ~ DOC String ~\\n\\nThe data used in the program is from the TV Series Game of Thrones which aired\\nfrom 2011 - 2019.The premise is several powerful families fight for control of\\nthe Seven Kingdoms.There are a total of 73 episodes in which there have been \\n1k+ of characters throughout  the series. \\n\\nThis program is designed to remove null values from features and fill with\\nappropriate metrics.The program consists of two model types, \\nLogistic Regression & Classification Trees.Each model type has its own \\nfunctions for hyperparameter tuning. The models produce a confusion matrix,\\ntraining, testing, and AUC scores.\\n\\nExtra Information:\\nhttps://en.wikipedia.org/wiki/Game_of_Thrones\\nhttps://www.imdb.com/title/tt0944947/\\n\\nNo known bugs or Errors\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    ~ DOC String ~\n",
    "\n",
    "The data used in the program is from the TV Series Game of Thrones which aired\n",
    "from 2011 - 2019.The premise is several powerful families fight for control of\n",
    "the Seven Kingdoms.There are a total of 73 episodes in which there have been \n",
    "1k+ of characters throughout  the series. \n",
    "\n",
    "This program is designed to remove null values from features and fill with\n",
    "appropriate metrics.The program consists of two model types, \n",
    "Logistic Regression & Classification Trees.Each model type has its own \n",
    "functions for hyperparameter tuning. The models produce a confusion matrix,\n",
    "training, testing, and AUC scores.\n",
    "\n",
    "Extra Information:\n",
    "https://en.wikipedia.org/wiki/Game_of_Thrones\n",
    "https://www.imdb.com/title/tt0944947/\n",
    "\n",
    "No known bugs or Errors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c00e15",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6cd2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries needed\n",
    "import pandas as pd # importing data science lib\n",
    "import numpy as np #importing math lib\n",
    "import matplotlib.pyplot as plt #importing data plotting lib\n",
    "import seaborn as sns # impirting enhanced graphics for plotting lib\n",
    "import gender_guesser.detector as gender # importing gener detector\n",
    "from sklearn.neighbors import KNeighborsRegressor # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import plot_tree                   # tree plots\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer #importing scoring models lib\n",
    "\n",
    "\n",
    "#custom function for helping in the tuning of hyper params\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('./analysis_images/Feature_Importance.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62dc59b",
   "metadata": {},
   "source": [
    "#  Data & File Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e529b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data inside a file variable\n",
    "file = \"./GOT_character_predictions.xlsx\"\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 900)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "#reading in the excel data and saving it in a variable\n",
    "got = pd.read_excel(io = file, header = 0, sheet_name = 0)\n",
    "\n",
    "\n",
    "#looping to creating new columns for missing values in existing features\n",
    "for col in got:\n",
    "    if got[col].isnull().astype(int).sum() > 0:\n",
    "        got['m_'+col] = got[col].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8f7b2",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349b8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the mode of titles in a variable\n",
    "title_mode = \"Ser\"\n",
    "# filling title NAs with mode\n",
    "got['title'].fillna(value = title_mode, inplace = True)\n",
    "\n",
    "#new feature to capture the dummies\n",
    "got[\"new_title\"] = 0\n",
    "#looping through to replace into dummies\n",
    "for i, value in got.iterrows():\n",
    "    if got.loc[i,\"title\"] == \"Ser\":\n",
    "        got.loc[i, \"new_title\"] = int(1)\n",
    "################################################### TITLE\n",
    "# filling house NAs with 0\n",
    "got['house'].fillna(value = 0,inplace = True)\n",
    "\n",
    "#creating new feature\n",
    "got[\"new_house\"] = 0\n",
    "\n",
    "#making the houses into dummy\n",
    "got.loc[got[\"house\"] == 0 , \"new_house\"] =0\n",
    "got.loc[got[\"house\"] != 0 , \"new_house\"] =1\n",
    "###################################################### HOUSE\n",
    "#instantiate a new temp feature\n",
    "got[\"new_culture\"] = 0\n",
    "\n",
    "#loop through all the rows in culture and set value accordinly\n",
    "for i, value in got.iterrows():\n",
    "    if got.loc[i,\"culture\"] == \"Northmen\":\n",
    "        got.loc[i, \"new_culture\"] = 1\n",
    "        \n",
    "    elif got.loc[i,\"culture\"] == \"Ironborn\":\n",
    "        got.loc[i, \"new_culture\"] = 1\n",
    "        \n",
    "    elif got.loc[i,\"culture\"] == \"Free Folk\":\n",
    "        got.loc[i, \"new_culture\"] = 1\n",
    "    \n",
    "    elif got.loc[i,\"culture\"] == \"Valyrian\":\n",
    "        got.loc[i, \"new_culture\"] = 1\n",
    "        \n",
    "    elif got.loc[i,\"culture\"] == \"Braavosi\":\n",
    "        got.loc[i, \"new_culture\"] = 1\n",
    "        \n",
    "#replacing the new feature into original col name       \n",
    "got[\"culture\"] = got[\"new_culture\"]\n",
    "###################################################### Culture\n",
    "\n",
    "#loop through all the rows in age and set value accordinly\n",
    "for i, value in got.iterrows():\n",
    "    if got.loc[i,\"age\"] <0 :\n",
    "        got.loc[i, \"age\"] = (got.loc[i,\"age\"]*-1)/10000\n",
    "        \n",
    "#saving the median age in variable\n",
    "age_median = round(got[\"age\"].median())\n",
    "\n",
    "#filling the missing values with the median age\n",
    "got['age'].fillna(value = age_median,inplace = True)\n",
    "\n",
    "###################################################### AGE\n",
    "\n",
    "# filling heir NAs with 0\n",
    "got['heir'].fillna(value = 0,inplace = True)\n",
    "\n",
    "#creating new feature\n",
    "got[\"new_heir\"] = 0\n",
    "\n",
    "#making the heir into dummy\n",
    "got.loc[got[\"heir\"] == 0 , \"new_heir\"] =0\n",
    "got.loc[got[\"heir\"] != 0 , \"new_heir\"] =1\n",
    "###################################################### Heir\n",
    "\n",
    "#correlation was very weak\n",
    "#got[\"rel_person\"] = 1\n",
    "\n",
    "#for index, name in got.iterrows():      \n",
    "#    if got.loc[index, \"gender_guess\"]== \"unknown\":\n",
    "#        got.loc[index,\"rel_person\"] = 0\n",
    " ###################################################### Gender Guess       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb11c23",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e10b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combination of all the books\n",
    "got[\"all_books\"]= got[\"book1_A_Game_Of_Thrones\"] + got[\"book2_A_Clash_Of_Kings\"]+ \\\n",
    "got[\"book3_A_Storm_Of_Swords\"] + got[\"book4_A_Feast_For_Crows\"]+ \\\n",
    "got[\"book5_A_Dance_with_Dragons\"]         #Na\n",
    "\n",
    "#combination of the two highest correlated books\n",
    "got[\"book_1_4\"] = got[\"book1_A_Game_Of_Thrones\"] + got[\"book4_A_Feast_For_Crows\"] #na\n",
    "\n",
    "#feature for age and married\n",
    "got[\"age_married\"] = got[\"age\"] + got[\"isMarried\"] #na\n",
    "\n",
    "#feature for house and heir\n",
    "got[\"house_heir\"] = got[\"new_house\"] + got[\"new_heir\"] #na\n",
    "#feature for house and title\n",
    "got[\"house_title\"] = got[\"new_house\"] + got[\"new_title\"] #no correlation\n",
    "#feature for age and number of dead relations\n",
    "got[\"dead_age\"] = got[\"age\"] * got[\"numDeadRelations\"] #marginal\n",
    "#feature for popularity and house\n",
    "got[\"pop_house\"] = got[\"popularity\"] * got[\"new_house\"] #na\n",
    "\n",
    "# feature for missing title - missing house - missing culture\n",
    "got[\"house_cult_title\"] = got[\"m_title\"] + got[\"m_house\"] + got[\"m_culture\"] #marginal\n",
    "\n",
    "#feature for LOG of age \n",
    "got[\"log_age\"] = np.log(got[\"age\"]+0.000001)\n",
    "\n",
    "#dividing age into above and below the feature mean\n",
    "got[\"split_age\"] = 0\n",
    "mean_age = round(got[\"age\"].mean(),0)\n",
    "#looping through all the observations\n",
    "for index, x in got.iterrows():      #marginal at best\n",
    "    if got.loc[index, \"age\"]>= mean_age:\n",
    "        got.loc[index,\"split_age\"] = 1\n",
    "        \n",
    "#inversie of popularity feature\n",
    "got[\"unpopular\"] = 1- got[\"popularity\"]\n",
    "#log of popularity\n",
    "got[\"log_popularity\"] = np.log(got[\"popularity\"]+0.001) #HIGH CORR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce027da6",
   "metadata": {},
   "source": [
    "# Dropping Non-Valuable Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381941e",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "These are not relevant as they would not impact logically if the current person is alive or not. \n",
    "\n",
    "1)isAliveFather 2)  isAliveHeir 3)  isAliveMother 4)  isAliveSpouse               \n",
    "\n",
    "These are not relevant because another category already accounts for this information. such as birthday and age are the same data point essentially only in different forms. \n",
    "\n",
    "-dateOfBirth       \n",
    "-spouse    \n",
    "\n",
    "These have to little data to do anything relevant. \n",
    "-Father\n",
    "-Mother\n",
    "\n",
    "Produces a weak correlation to the Response Variable and processing time takes to long.\n",
    "\n",
    "Male (Using Gender Guesser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d4644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a copy of the data set\n",
    "got_copy = got.copy(deep = False)\n",
    "\n",
    "#droping the columns that wont be used in models\n",
    "got_copy = got_copy.drop(columns =[\"dateOfBirth\",\"isAliveSpouse\" ,\"spouse\" ,\"isAliveFather\",\n",
    "              \"father\",\"isAliveHeir\",\"isAliveMother\", \"mother\"],\n",
    "              axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3761d",
   "metadata": {},
   "source": [
    "# Dictionary of Response Variables & Setting Train Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2421fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict for testing multiple x variable combinations\n",
    "got_copy_dict = {\n",
    "    \n",
    "    'test_1': ['book4_A_Feast_For_Crows', \n",
    "                'm_age', 'age', 'popularity'],\n",
    "                \n",
    "    'test_2':  [  \"book1_A_Game_Of_Thrones\",\"numDeadRelations\",\"m_age\",\n",
    "                            \"book4_A_Feast_For_Crows\",\"new_heir\",\"popularity\" ],\n",
    "    \n",
    "    'test_3':  [  \"book1_A_Game_Of_Thrones\",\"numDeadRelations\",\"m_age\",\n",
    "                            \"book4_A_Feast_For_Crows\",\"new_heir\",\"popularity\" ],\n",
    "    \n",
    "    'test_4': ['book4_A_Feast_For_Crows', \n",
    "                 'age_married','log_popularity','dead_age']\n",
    "}\n",
    "#preparing the x variables\n",
    "got_copy_data   =  got_copy.loc[ : , got_copy_dict[\"test_4\"]]\n",
    "#preparing the response variable \n",
    "got_copy_target = got_copy.loc[:, \"isAlive\"]\n",
    "\n",
    "\n",
    "#setting up the train test split with given params\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_copy_data,\n",
    "            got_copy_target,\n",
    "            test_size = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify = got_copy_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb16d4b",
   "metadata": {},
   "source": [
    "# Logistic Regression &  Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be721cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'warm_start': True, 'tol': 2.17, 'solver': 'lbfgs', 'max_iter': 800, 'C': 3.9000000000000004}\n",
      "Tuned CV AUC      : 0.6342\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# declaring a hyperparameter space\n",
    "C_range          = np.arange(0.1, 5.0, 0.1)\n",
    "warm_start_range = [True, False]\n",
    "solver_range     = ['newton-cg', 'sag', 'lbfgs','saga']\n",
    "max_iter_range    = np.arange(600,1000,100) \n",
    "tot               =  np.arange(0.01,3,0.01)\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_range,\n",
    "              'warm_start' : warm_start_range,\n",
    "              'solver'     : solver_range,\n",
    "              'max_iter'   : max_iter_range,\n",
    "                'tol'       : tot}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(got_copy_data, got_copy_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c17e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG REGRESSION\n",
      "Training ACCURACY: 0.7778\n",
      "Testing  ACCURACY: 0.8513\n",
      "[[ 24  26]\n",
      " [  3 142]]\n",
      "\n",
      "True Negatives : 24\n",
      "False Positives: 26\n",
      "False Negatives: 3\n",
      "True Positives : 142\n",
      "\n",
      "AUC\n",
      "0.7297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#instantiating the model for logistic regression \n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 3.9,\n",
    "                            max_iter= 800,\n",
    "                            warm_start= True,\n",
    "                            random_state = 219,\n",
    "                           tol = 2.17)\n",
    "\n",
    "\n",
    "#fitting the training data for the model\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#predicting for the model based on test set \n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring and printing the results\n",
    "print(\"LOG REGRESSION\")\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "#saving the score data in a variable\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "#printing out a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))\n",
    "\n",
    "# saving the confusion matrix in multiple variables\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "#printing the confusion matrix out in a better format\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")\n",
    "\n",
    "#Printing out the AUC score\n",
    "print(\"AUC\")\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "#saving AUC score in a variable\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6179e63",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e4db98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameters  : {'splitter': 'best', 'min_samples_split': 35, 'min_samples_leaf': 29, 'max_features': 'auto', 'max_depth': 6, 'criterion': 'entropy'}\n",
      "Tuned CV AUC      : 0.6626\n"
     ]
    }
   ],
   "source": [
    "# declaring a hyperparameter space\n",
    "criterion = ['gini', 'entropy']\n",
    "split     = ['best', 'random']\n",
    "depth     = np.arange(1, 8, 1)\n",
    "min_samples_leaf      = np.arange(1, 100, 1)\n",
    "min_impurity_decrease      =np.arange(0,1,0.05)\n",
    "min_samples_split     = np.arange(30,120,1)\n",
    "max_feat = [\"auto\",\"sqrt\",\"log2\"]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion,\n",
    "              'splitter'         : split,\n",
    "              'max_depth'        : depth,\n",
    "             \"max_features\"      : max_feat,\n",
    "             \"min_samples_split\" : min_samples_split,\n",
    "            \"min_samples_leaf\"   :  min_samples_leaf   }\n",
    "\n",
    " # INSTANTIATING the model object without hyperparameters\n",
    "DT_tuned = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    " # GridSearchCV object\n",
    "DT_tuned_cv = RandomizedSearchCV(estimator           = DT_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "DT_tuned_cv.fit(got_copy_data, got_copy_target)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", DT_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", DT_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "785e6ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUNED TREE\n",
      "Training ACCURACY: 0.8\n",
      "Testing  ACCURACY: 0.7881\n",
      "AUC Score        : 0.6231\n",
      "\n",
      "True Negatives : 13\n",
      "False Positives: 37\n",
      "False Negatives: 2\n",
      "True Positives : 143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth= 5,\n",
    "                    min_samples_leaf= 1,\n",
    "                    random_state = 219,\n",
    "                    splitter = \"best\",\n",
    "                    max_features= \"sqrt\",\n",
    "                    criterion = \"entropy\",\n",
    "                    min_samples_split= 36)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "tree_pruned_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "tree_prune_pred = tree_pruned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print(\"PRUNED TREE\")\n",
    "print('Training ACCURACY:', tree_pruned_fit.score(x_test,y_test).round(4))\n",
    "print('Testing  ACCURACY:', tree_pruned_fit.score(x_train, y_train).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_prune_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = tree_pruned_fit.score(x_test,y_test).round(4) # accuracy\n",
    "pruned_tree_test_score  = tree_pruned_fit.score(x_train, y_train).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = tree_prune_pred) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_prune_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b38b34",
   "metadata": {},
   "source": [
    "# Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff3ca341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a Pearson Corr to check against the response variable\n",
    "#got_copy_corr = got.corr(method = \"pearson\").round(2)\n",
    "\n",
    "#got_copy_corr[\"isAlive\"].sort_values(ascending = True)\n",
    "\n",
    "#got_copy.isnull().sum().sort_values(ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importances\n",
    "#plot_feature_importances(model = tree_pruned, train = x_train, export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64a9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Used to plot any feature in order to look for swekness\n",
    "# mean = round(got_copy[\"log_popularity\"].mean(),3)\n",
    "# #instantiating the plot\n",
    "# sns.histplot(data = got_copy, x = \"log_popularity\",kde = True, color = \"red\")\n",
    "# #creating a vertical line drawn at the mean\n",
    "# plt.axvline(mean,\n",
    "#             color = \"green\",\n",
    "#                 ls = \":\")\n",
    "# #showing the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683cf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#would be used for gender guesser in the mdoel if it was of high correlation\n",
    "# lst = []\n",
    "\n",
    "# for i, col in got.iterrows():\n",
    "\n",
    "#     # splitting email domain at '@'\n",
    "#     split_name = got.loc[i, 'name'].split(sep = \" \")\n",
    "\n",
    "#     # appending placeholder_lst with the results\n",
    "#     lst.append(split_name)\n",
    "\n",
    "\n",
    "# # converting placeholder_lst into a DataFrame \n",
    "# split_name = pd.DataFrame(lst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# got[\"split_name\"] = split_name[0]\n",
    "\n",
    "# got[\"split_name\"].head()\n",
    "\n",
    "# # placeholder list\n",
    "# placeholder_lst = []\n",
    "\n",
    "\n",
    "# # looping to guess gender\n",
    "# for name in got['split_name']:\n",
    "#     guess = gender.Detector().get_gender(name)\n",
    "#     placeholder_lst.append(guess)\n",
    "\n",
    "#  #converting list into a series\n",
    "# got['gender_guess'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a616d13",
   "metadata": {},
   "source": [
    "# Final Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e1aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|     Model Name               Training Accuracy     Testing Accuracy     AUC Score     Confusion Matrix:  TN,FP,FN,TP|\n",
      "|     ----------               ------------------    -----------------    ----------     -----------------------------|\n",
      "|Classification Trees - Pruned    0.8              0.7881                 0.623          (13, 37, 2, 143)             |\n",
      "|                                                                                                                     |                                        \n",
      "|---------------------------------------------------------------------------------------------------------------------|\n",
      "|                                                                                                                     |\n",
      "|Logistic Regression (FINAL)      0.7778              0.8513                0.7297       (24, 26, 3, 142)             |\n"
     ]
    }
   ],
   "source": [
    "#producing results table for model outputs\n",
    "print(f\"\"\"\n",
    "|     Model Name               Training Accuracy     Testing Accuracy     AUC Score     Confusion Matrix:  TN,FP,FN,TP|\n",
    "|     ----------               ------------------    -----------------    ----------     -----------------------------|\n",
    "|Classification Trees - Pruned    {pruned_tree_train_score}              {pruned_tree_test_score}                 {pruned_tree_auc_score.round(3)}          {pruned_tree_tn,pruned_tree_fp,pruned_tree_fn,pruned_tree_tp}             |\n",
    "|                                                                                                                     |                                        \n",
    "|---------------------------------------------------------------------------------------------------------------------|\n",
    "|                                                                                                                     |\n",
    "|Logistic Regression (FINAL)      {logreg_train_score}              {logreg_test_score}                {logreg_auc_score}       {logreg_tn,logreg_fp,logreg_fn,logreg_tp}             |\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6110b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ea873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
